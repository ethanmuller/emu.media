<!DOCTYPE html>
<html lang="en-US">
  <head>
    <title>moufs</title>

    <!-- this prevents a dorky zoomed-out page on mobile -->
    <meta name="viewport" content="width=device-width,initial-scale=1.0">

    <!-- this tells the browser which characters we're using -->
    <meta charset="UTF-8">

    <!-- this gets us nice fonts -->
    <link rel="preconnect" href="https://fonts.gstatic.com">
    <link href="https://fonts.googleapis.com/css2?family=IBM+Plex+Mono:wght@300&display=swap" rel="stylesheet">


    <style>
      body {
          padding: 0;
          margin: 0;
      }
      .wrapper {
          display: inline-block;
          position: relative;
      }

      canvas {
          background: black;
          display: block;
      }
      .lds-roller {
          display: none;
          width: 80px;
          height: 80px;

          position: absolute;
          top: 50%;
          left: 50%;
          transform: translate(-50%, -50%);
      }

      .is-loading .lds-roller {
          display: inline-block;
      }
      .lds-roller div {
          animation: lds-roller 1.2s cubic-bezier(0.5, 0, 0.5, 1) infinite;
          transform-origin: 40px 40px;
      }
      .lds-roller div:after {
          content: " ";
          display: block;
          position: absolute;
          width: 7px;
          height: 7px;
          border-radius: 50%;
          background: #fff;
          margin: -4px 0 0 -4px;
      }
      .lds-roller div:nth-child(1) {
          animation-delay: -0.036s;
      }
      .lds-roller div:nth-child(1):after {
          top: 63px;
          left: 63px;
      }
      .lds-roller div:nth-child(2) {
          animation-delay: -0.072s;
      }
      .lds-roller div:nth-child(2):after {
          top: 68px;
          left: 56px;
      }
      .lds-roller div:nth-child(3) {
          animation-delay: -0.108s;
      }
      .lds-roller div:nth-child(3):after {
          top: 71px;
          left: 48px;
      }
      .lds-roller div:nth-child(4) {
          animation-delay: -0.144s;
      }
      .lds-roller div:nth-child(4):after {
          top: 72px;
          left: 40px;
      }
      .lds-roller div:nth-child(5) {
          animation-delay: -0.18s;
      }
      .lds-roller div:nth-child(5):after {
          top: 71px;
          left: 32px;
      }
      .lds-roller div:nth-child(6) {
          animation-delay: -0.216s;
      }
      .lds-roller div:nth-child(6):after {
          top: 68px;
          left: 24px;
      }
      .lds-roller div:nth-child(7) {
          animation-delay: -0.252s;
      }
      .lds-roller div:nth-child(7):after {
          top: 63px;
          left: 17px;
      }
      .lds-roller div:nth-child(8) {
          animation-delay: -0.288s;
      }
      .lds-roller div:nth-child(8):after {
          top: 56px;
          left: 12px;
      }
      @keyframes lds-roller {
          0% {
              transform: rotate(0deg);
          }
          100% {
              transform: rotate(360deg);
          }
      }
    </style>

  </head>

  <body>
    <div class="wrapper is-loading">
      <canvas width="300" height="300"></canvas>
      <video hidden></video>
      <div class="lds-roller"><div></div><div></div><div></div><div></div><div></div><div></div><div></div><div></div></div>
    </div>

    <!-- Require the peer dependencies of face-landmarks-detection. -->
    <script src="https://unpkg.com/@tensorflow/tfjs-core@2.4.0/dist/tf-core.js"></script>
    <script src="https://unpkg.com/@tensorflow/tfjs-converter@2.4.0/dist/tf-converter.js"></script>

    <!-- You must explicitly require a TF.js backend if you're not using the tfjs union bundle. -->
    <script src="https://unpkg.com/@tensorflow/tfjs-backend-webgl@2.4.0/dist/tf-backend-webgl.js"></script>
    <!-- Alternatively you can use the WASM backend: <script src="https://unpkg.com/@tensorflow/tfjs-backend-wasm@2.4.0/dist/tf-backend-wasm.js"></script> -->

    <!-- Require face-landmarks-detection itself. -->
    <script src="https://unpkg.com/@tensorflow-models/face-landmarks-detection@0.0.1/dist/face-landmarks-detection.js"></script>


    <script>
      var video = document.querySelector('video');
      video.setAttribute("playsinline", true);
      let model

      const canvas = document.querySelector('canvas');

      const ctx = canvas.getContext('2d');

      // let hasRendered = false

      const wrapper = document.querySelector('.wrapper')

      let o = 0

      // ctx.fillRect(10, 10, 150, 100);

      const drawPoint = (x, y) => {
        ctx.fillStyle = 'white';
        ctx.beginPath()
        ctx.arc(x, y, 3, 0, 2 * Math.PI);
        ctx.fill()
      }

      const constraints = {
          video: { facingMode: "user" },
      }
      navigator.mediaDevices.getUserMedia(constraints)
               .then(function(stream) {
                   // Older browsers may not have srcObject
                   if ("srcObject" in video) {
                       video.srcObject = stream;
                   }

                   video.onloadedmetadata = function(e) {
                       video.play();
                   };
               })
               .catch(function(err) {
                   /* handle the error */
               });


      

      async function renderFace() {

          // Pass in a video stream (or an image, canvas, or 3D tensor) to obtain an
          // array of detected faces from the MediaPipe graph. If passing in a video
          // stream, a single prediction per frame will be returned.
          const predictions = await model.estimateFaces({
              input: video,
              predictIrises: false,
          });

          // hasRendered = true
          wrapper.classList.remove('is-loading')

          ctx.clearRect(0, 0, canvas.width, canvas.height);

          if (predictions.length > 0) {
              for (let i = 0; i < predictions.length; i++) {
                  const keypoints = predictions[i].scaledMesh;
                  const topLip = keypoints[13]
                  const bottomLip = keypoints[14]
                  const septum = keypoints[2]
                  const [x1, y1] = topLip
                  const [x2, y2] = bottomLip
                  const [x3, y3] = septum
                  const opennessThresholdA = 0.3
                  const opennessThresholdB = 0.6

                  const lipsDistance = Math.sqrt(Math.pow(x2-x1, 2)+Math.pow(y2-y1,2));
                  // console.log(lipsDistance)

                  const topLipSeptumDistance = Math.sqrt(Math.pow(x3-x1, 2)+Math.pow(y3-y1,2));
                  const openness = lipsDistance / topLipSeptumDistance;

                  const dO = o - openness
                  o -= dO * 0.2

                  if (o > opennessThresholdB) {
                      ctx.fillStyle = 'red'
                      ctx.fillRect(0, 0, canvas.width, canvas.height)
                  } else if (o > opennessThresholdA && false) {
                      ctx.fillStyle = 'blue'
                      ctx.fillRect(0, 0, canvas.width, canvas.height)
                  }

                  // ctx.fillStyle = 'white'
                  // ctx.fillRect(0, 0, 8, canvas.height * o)

                  // ctx.lineWidth = 2
                  // ctx.strokeStyle = 'blue'
                  // ctx.beginPath()
                  // ctx.arc(100, 100, 100 * opennessThresholdA, 0, 2 * Math.PI);
                  // ctx.stroke()

                  ctx.lineWidth = 2
                  ctx.strokeStyle = 'red'
                  ctx.beginPath()
                  ctx.arc(100, 100, 100 * opennessThresholdB, 0, 2 * Math.PI);
                  ctx.stroke()
                       ctx.fillStyle = 'white';
                       ctx.font = "16px monospace";
                  ctx.fillText('OPENNESS', 100 + 100 * o + 10, 105);

                  ctx.fillStyle = 'white'
                  ctx.beginPath()
                  ctx.arc(100, 100, 100 * o, 0, 2 * Math.PI);
                  ctx.fill()
                  // ctx.fillStyle = 'white';
                  // ctx.fill()


                  // drawPoint(keypoints[3][0], keypoints[3][1])
                  // drawPoint(keypoints[4][0], keypoints[4][1])

                  // Log facial keypoints.
                   for (let i = 0; i < keypoints.length; i++) {

                   const [x, y, z] = keypoints[i];
                       drawPoint(x, y)
                       // ctx.fillStyle = 'white';
                       // ctx.font = "8px monospace";
                       // ctx.fillText(i, x, y);

                       // console.log(`Keypoint ${i}: [${x}, ${y}, ${z}]`);
                   }
                  
                  // ctx.fillStyle = 'red';
                  // ctx.beginPath()
                  // ctx.arc(x1, y1, 3, 0, 2 * Math.PI);
                  // ctx.fill()
                  
                  // ctx.fillStyle = 'white';
                  // ctx.beginPath()
                  // ctx.arc(x2, y2, 3, 0, 2 * Math.PI);
                  // ctx.fill()

              }
          }
          window.requestAnimationFrame(renderFace)
      }

      async function setup() {
        canvas.width = video.videoWidth * 2
        canvas.height = video.videoHeight * 2

          // Load the MediaPipe Facemesh package.
          model = await faceLandmarksDetection.load(
              faceLandmarksDetection.SupportedPackages.mediapipeFacemesh);

          // canvas.addEventListener('click', renderFace)
          window.requestAnimationFrame(renderFace)
      }

      video.addEventListener('loadeddata', setup)
      
    </script>
  </body>
</html>
